

<table>
    <tr>
        <td>


# The Envision Toolbox
The envision toolbox contains coding modules and lectures that are tailored for the study of multimodal human behavior. The modules are intended as pedagogical examples to get researchers started on a particular mode of inquiry. The envision toolbox is for everyone, by everyone, in the hope that it will become a community of multimodal researchers and developers.  

# How to
If you want to start to explore the envision toolbox in a hands-on way we advise you to download/clone the repository in its entirety (https://github.com/WimPouw/EnvisionBootcamp2021). In the Python and R folders you will find folders that contain a single “module”, containing notebooks and sample data, so that each module can be run in a self-sufficient way.   

If you just want to quickly overview the different coding modules of the envision toolbox without downloading the whole repository you can go to: https://wimpouw.github.io/EnvisionBootcamp2021/

You can reuse and adapt the code in any way. 

# Background
The analysis of (non-)human animal communication requires taking into account a multitude of signaling modes, including communicative content and prosody, manual, facial, and whole body gesturing, interactive aspects between persons such as turn taking, and an almost infinite other more or less subtle ways of languaging and signaling. We as researchers of human communication are still daunted by the complexity of it all, and there is a long way to go before the right tools and granularity are found to understand human communication. Central challenges in this respect are ways to connect quantitative tools and qualitative insights - not to forget that what you want to measure does not equal your measurement. Another challenge is to build tools which are contextualized in a way that new students can start to adopt, tinker and refine them further. The envision toolbox is aimed to provide a pedagogical platform for students of multimodal behavior who aim to use quantitative tools next to, or in harmony with, their qualitative research questions.  

The launch of the envision toolbox 8-10 December in Potsdam, and the video materials that contextualize the contents of the toolbox are (will be) shared via links in the coding modules.

# Radical openness and collaboration
Our hope for the further development of the envision toolbox is that we build an open science community of researchers and developers that would like to build research tools and contextualize them in a pedagogical way so as to allow people to learn how to wield such tools. This means that we will keep further developing the toolbox, expanding it with more modules, and improving the general platform. This also means that we are always looking for new team members who would like to improve, correct, an existing module, or contribute their own module that they would like to share and host on the platform (that future others may then in turn improve further too). If you would like to contribute something and want to contribute to the github repository please contact us (wim.pouw@donders.ru.nl & james.trujillo@donders.ru.nl). Each module will have its own citation, so that new team members can be appropriately acknowledged for their work.

# Citation
Each coding module has its own website citation so that the coders can be acknowledged individually for their work on a particular module. In that way, if new coders join the project they can start to contribute their own module, or correct and enhance existing modules. However, if you want a general citation of the project organization and toolbox below is the general citation.

General citation: 

Cwieck, O., De Melo, G., Edelman, J., Owoyele, B., Pouw, W., Santuber, J. Trujillo, J.. Envision Toolbox: Multimodal (Signal) Processing and Analysis in Communication. https://github.com/WimPouw/EnvisionBootcamp2021 
 (**Alphabetical order) 
 
# Funding
 This work has been supported by a VENI grant (VI.Veni.201G.047) awarded by the Dutch Research Council (NWO) to Wim Pouw (PI). This work has further been supported by the Hasso-Plattner Foundation.
        
 </td>
       
</tr>
</table>


