{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Body Tracking Using MediaPipe  </h1>\n",
    "\n",
    "\n",
    "<h3> \n",
    "    Wim Pouw ( wim.pouw@donders.ru.nl )<br>James Trujillo ( james.trujillo@donders.ru.nl )<br>\n",
    "    18-11-2021 </h3>\n",
    "    \n",
    "<img src=\"./images/BOOTCAMP.png\"> </center>\n",
    "\n",
    "<h3> Info documents </h3>\n",
    "This module provides a simple demonstration of how to use MediaPipe for motion tracking of a single person. The approach provides a lightweight motion tracking solution, and several distinct advantages in the type of output that we get\n",
    "<br><br>\n",
    "\n",
    "* location code: \n",
    "https://github.com/WimPouw/EnvisionBootcamp2021/tree/main/Python/MediaBodyTracking\n",
    "\n",
    "* citation: \n",
    "Pouw, W.  &  Trujillo, J.P.(2021-11-18). <i> Body Tracking Using MediaPipe </i> \\[day you visited the site]. Retrieved from: https://github.com/WimPouw/EnvisionBootcamp2021/tree/main/Python/MediaBodyTracking \n",
    "\n",
    "<h4>resources</h4>\n",
    "\n",
    "* https://google.github.io/mediapipe/solutions/pose.html\n",
    "\n",
    "* https://github.com/google/mediapipe\n",
    "<br><br>\n",
    "* Lugaresi, C., Tang, J., Nash, H., McClanahan, C., Uboweja, E., Hays, M., ... & Grundmann, M. (2019). Mediapipe: A framework for building perception pipelines. arXiv preprint arXiv:1906.08172.\n",
    "<br>\n",
    "<h4>Required</h4>\n",
    "Before you start, make sure the following python packages are installed:\n",
    "\n",
    "* opencv-python\n",
    "* mediapipe\n",
    "* numpy\n",
    "* pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import cv2\n",
    "import mediapipe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    " \n",
    "drawingModule = mediapipe.solutions.drawing_utils #from mediapipe initialize a module that we will use\n",
    "poseModule = mediapipe.solutions.pose             #from mediapipe initialize a module that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all videos in mediafolder\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"./MediaToAnalyze/\" #this is your folder with (all) your video(s)\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))] #loop through the filenames and collect them in a list\n",
    "#time series output folder\n",
    "foldtime = \"./Timeseries_Output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################some preperatory functions and lists for saving the data\n",
    "\n",
    "#take some google classification object and convert it into a string\n",
    "def makegoginto_str(gogobj):\n",
    "    gogobj = str(gogobj).strip(\"[]\")\n",
    "    gogobj = gogobj.split(\"\\n\")\n",
    "    return(gogobj[:-1]) #ignore last element as this has nothing\n",
    "\n",
    "#landmarks 33x that are used by Mediapipe (Blazepose)\n",
    "markers = ['NOSE', 'LEFT_EYE_INNER', 'LEFT_EYE', 'LEFT_EYE_OUTER', 'RIGHT_EYE_OUTER', 'RIGHT_EYE', 'RIGHT_EYE_OUTER',\n",
    "          'LEFT_EAR', 'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT', 'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW', \n",
    "          'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX',\n",
    "          'LEFT_THUMB', 'RIGHT_THUMB', 'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE',\n",
    "          'LEFT_HEEL', 'RIGHT_HEEL', 'LEFT_FOOT_INDEX', 'RIGHT_FOOT_INDEX']\n",
    "\n",
    "#check if there are numbers in a string\n",
    "def num_there(s):\n",
    "    return any(i.isdigit() for i in s)\n",
    "\n",
    "#make the stringifyd position traces into clean numerical values\n",
    "def listpostions(newsamplemarks):\n",
    "    tracking_p = []\n",
    "    for value in newsamplelmarks:\n",
    "        if num_there(value):\n",
    "            stripped = value.split(':', 1)[1]\n",
    "            stripped = stripped.strip() #remove spaces in the string if present\n",
    "            tracking_p.append(stripped) #add to this list  \n",
    "    return(tracking_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our preparatory functions set and packages loaded. We can get to tracking. In the code block below, we will do 3 things. The code will perform the actual tracking using MediaPipe (functions such as <i> pose, posemodule</i>), draw the tracked points back onto each frame of the video (using <i>cv2</i>), and save the coordinates of the tracked points into a dataframe (using <i>pandas</i>) for analysis or further processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250.0 480.0 30.0\n"
     ]
    }
   ],
   "source": [
    "#loop through all the video files and extract pose information\n",
    "for ff in onlyfiles:\n",
    "    #capture the video, and check video settings\n",
    "    capture = cv2.VideoCapture(mypath+ff)\n",
    "    frameWidth = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    frameHeight = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    fps = capture.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "    print(frameWidth, frameHeight, fps)\n",
    "    #pose tracking with keypoints save!\n",
    "    \n",
    "    #make an 'empty' video file where we project the poste tracking on\n",
    "    samplerate = fps #make the same as current video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V') #(*'XVID')\n",
    "    out = cv2.VideoWriter('Videotracking_output/'+ff[:-4]+'.mp4', fourcc, fps = samplerate, frameSize = (int(frameWidth), int(frameHeight)))\n",
    "\n",
    "    #make a variable list with x, y, z, info where data is appended to\n",
    "        #the markers are initialized above\n",
    "    markerxyz = []\n",
    "    for mark in markers:\n",
    "        for pos in ['X', 'Y', 'Z', 'visibility']:\n",
    "            nm = pos + \"_\" + mark\n",
    "            markerxyz.append(nm)\n",
    "    addvariable = ['time']\n",
    "    addvariable.extend(markerxyz)\n",
    "\n",
    "    time = 0 #initalize a time variable that starts at 0\n",
    "    timeseries = [addvariable] #add the first row of column names to your timeseres data object (X_NOSE, .. etc.)\n",
    "    #MAIN ROUTINE\n",
    "        #check the settings of your posemodel if you want to finetune (https://google.github.io/mediapipe/solutions/pose.html)\n",
    "    with poseModule.Pose(min_detection_confidence=0.5, model_complexity = 1, min_tracking_confidence=0.75, smooth_landmarks = True) as pose:\n",
    "         while (True):\n",
    "            ret, frame = capture.read() #read frames\n",
    "            if ret == True:\n",
    "                results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) #apply the mediapipe pose tracking ont the frame\n",
    "                if results.pose_landmarks != None: #get the ddata from the results if there is info\n",
    "                    newsamplelmarks = makegoginto_str(results.pose_world_landmarks)\n",
    "                    newsamplelmarks = listpostions(newsamplelmarks)\n",
    "                    fuldataslice = [str(time)] #this is the first info in the time series slice (time)\n",
    "                    fuldataslice.extend(newsamplelmarks) #add positions to this slice\n",
    "                    timeseries.append(fuldataslice) #append slice to the timeries data object            \n",
    "                    drawingModule.draw_landmarks(frame, results.pose_landmarks, poseModule.POSE_CONNECTIONS) #draw skeleton\n",
    "                    #for point in handsModule.HandLandmark: #you can uncomments this if you want to draw points instead of skeleton\n",
    "                        #normalizedLandmark = results.pose_landmarks.landmark[point]\n",
    "                        #pixelCoordinatesLandmark = drawingModule._normalized_to_pixel_coordinates(normalizedLandmark.x, normalizedLandmark.y, frameWidth, frameHeight)\n",
    "                        #cv2.circle(frame, pixelCoordinatesLandmark, 5, (0, 255, 0), -1)\n",
    "                cv2.imshow('MediaPipe Pose', frame) #show the current frame wiht skeleton tracking\n",
    "                out.write(frame)  ######write the frame to your video object######################comment this if you dont want to make a video\n",
    "                time = time+(1000/samplerate) #routine is done, next frame will be 1000 milliseconds/samplerate later in time\n",
    "                if cv2.waitKey(1) == 27: #allow the use of ESCAPE to break the loop\n",
    "                    break\n",
    "            if ret == False: #if there are no more frames, break the loop\n",
    "                break\n",
    "    #once done de-initialize\n",
    "    out.release()\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    ####################################################### data to be written row-wise in csv fil\n",
    "    # opening the csv file in 'w+' mode\n",
    "    file = open(foldtime + ff[:-4]+'.csv', 'w+', newline ='')\n",
    "    #write it\n",
    "    with file:    \n",
    "        write = csv.writer(file)\n",
    "        write.writerows(timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a sample frame from the output video: <br>\n",
    "<img src=\"./images/mediapipe_body.png\"> </center> <br>\n",
    "As well as a sample of the data that we produced:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>X_NOSE</th>\n",
       "      <th>Y_NOSE</th>\n",
       "      <th>Z_NOSE</th>\n",
       "      <th>visibility_NOSE</th>\n",
       "      <th>X_LEFT_EYE_INNER</th>\n",
       "      <th>Y_LEFT_EYE_INNER</th>\n",
       "      <th>Z_LEFT_EYE_INNER</th>\n",
       "      <th>visibility_LEFT_EYE_INNER</th>\n",
       "      <th>X_LEFT_EYE</th>\n",
       "      <th>...</th>\n",
       "      <th>Z_RIGHT_HEEL</th>\n",
       "      <th>visibility_RIGHT_HEEL</th>\n",
       "      <th>X_LEFT_FOOT_INDEX</th>\n",
       "      <th>Y_LEFT_FOOT_INDEX</th>\n",
       "      <th>Z_LEFT_FOOT_INDEX</th>\n",
       "      <th>visibility_LEFT_FOOT_INDEX</th>\n",
       "      <th>X_RIGHT_FOOT_INDEX</th>\n",
       "      <th>Y_RIGHT_FOOT_INDEX</th>\n",
       "      <th>Z_RIGHT_FOOT_INDEX</th>\n",
       "      <th>visibility_RIGHT_FOOT_INDEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.063733</td>\n",
       "      <td>0.502805</td>\n",
       "      <td>-0.395698</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>-0.083962</td>\n",
       "      <td>0.538291</td>\n",
       "      <td>-0.383986</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>-0.083089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130854</td>\n",
       "      <td>0.192507</td>\n",
       "      <td>0.018961</td>\n",
       "      <td>-0.489134</td>\n",
       "      <td>-0.100693</td>\n",
       "      <td>0.418703</td>\n",
       "      <td>-0.002238</td>\n",
       "      <td>-0.516333</td>\n",
       "      <td>0.090475</td>\n",
       "      <td>0.193644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>-0.043211</td>\n",
       "      <td>0.502240</td>\n",
       "      <td>-0.394696</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>-0.071669</td>\n",
       "      <td>0.535697</td>\n",
       "      <td>-0.384011</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>-0.070713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119296</td>\n",
       "      <td>0.194849</td>\n",
       "      <td>0.034104</td>\n",
       "      <td>-0.402429</td>\n",
       "      <td>0.040178</td>\n",
       "      <td>0.397703</td>\n",
       "      <td>-0.005346</td>\n",
       "      <td>-0.358187</td>\n",
       "      <td>0.092969</td>\n",
       "      <td>0.195986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.666667</td>\n",
       "      <td>-0.020163</td>\n",
       "      <td>0.503504</td>\n",
       "      <td>-0.386350</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>-0.051884</td>\n",
       "      <td>0.535895</td>\n",
       "      <td>-0.380524</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>-0.050845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115370</td>\n",
       "      <td>0.193730</td>\n",
       "      <td>0.053036</td>\n",
       "      <td>-0.289042</td>\n",
       "      <td>0.061571</td>\n",
       "      <td>0.381764</td>\n",
       "      <td>-0.005315</td>\n",
       "      <td>-0.230478</td>\n",
       "      <td>0.111993</td>\n",
       "      <td>0.196811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.008440</td>\n",
       "      <td>0.533132</td>\n",
       "      <td>-0.351903</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>-0.043266</td>\n",
       "      <td>0.560953</td>\n",
       "      <td>-0.352411</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>-0.042234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198556</td>\n",
       "      <td>0.207998</td>\n",
       "      <td>0.045575</td>\n",
       "      <td>-0.337201</td>\n",
       "      <td>0.151154</td>\n",
       "      <td>0.368794</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>-0.334947</td>\n",
       "      <td>0.215761</td>\n",
       "      <td>0.206893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.559002</td>\n",
       "      <td>-0.262275</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>-0.036010</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>-0.269395</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>-0.035020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222347</td>\n",
       "      <td>0.214859</td>\n",
       "      <td>0.037744</td>\n",
       "      <td>-0.280906</td>\n",
       "      <td>0.162776</td>\n",
       "      <td>0.364183</td>\n",
       "      <td>0.015523</td>\n",
       "      <td>-0.267834</td>\n",
       "      <td>0.253445</td>\n",
       "      <td>0.212417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time    X_NOSE    Y_NOSE    Z_NOSE  visibility_NOSE  \\\n",
       "0    0.000000 -0.063733  0.502805 -0.395698         0.999921   \n",
       "1   33.333333 -0.043211  0.502240 -0.394696         0.999912   \n",
       "2   66.666667 -0.020163  0.503504 -0.386350         0.999909   \n",
       "3  100.000000 -0.008440  0.533132 -0.351903         0.999891   \n",
       "4  133.333333  0.002767  0.559002 -0.262275         0.999872   \n",
       "\n",
       "   X_LEFT_EYE_INNER  Y_LEFT_EYE_INNER  Z_LEFT_EYE_INNER  \\\n",
       "0         -0.083962          0.538291         -0.383986   \n",
       "1         -0.071669          0.535697         -0.384011   \n",
       "2         -0.051884          0.535895         -0.380524   \n",
       "3         -0.043266          0.560953         -0.352411   \n",
       "4         -0.036010          0.584854         -0.269395   \n",
       "\n",
       "   visibility_LEFT_EYE_INNER  X_LEFT_EYE  ...  Z_RIGHT_HEEL  \\\n",
       "0                   0.999944   -0.083089  ...      0.130854   \n",
       "1                   0.999936   -0.070713  ...      0.119296   \n",
       "2                   0.999936   -0.050845  ...      0.115370   \n",
       "3                   0.999932   -0.042234  ...      0.198556   \n",
       "4                   0.999932   -0.035020  ...      0.222347   \n",
       "\n",
       "   visibility_RIGHT_HEEL  X_LEFT_FOOT_INDEX  Y_LEFT_FOOT_INDEX  \\\n",
       "0               0.192507           0.018961          -0.489134   \n",
       "1               0.194849           0.034104          -0.402429   \n",
       "2               0.193730           0.053036          -0.289042   \n",
       "3               0.207998           0.045575          -0.337201   \n",
       "4               0.214859           0.037744          -0.280906   \n",
       "\n",
       "   Z_LEFT_FOOT_INDEX  visibility_LEFT_FOOT_INDEX  X_RIGHT_FOOT_INDEX  \\\n",
       "0          -0.100693                    0.418703           -0.002238   \n",
       "1           0.040178                    0.397703           -0.005346   \n",
       "2           0.061571                    0.381764           -0.005315   \n",
       "3           0.151154                    0.368794            0.006082   \n",
       "4           0.162776                    0.364183            0.015523   \n",
       "\n",
       "   Y_RIGHT_FOOT_INDEX  Z_RIGHT_FOOT_INDEX  visibility_RIGHT_FOOT_INDEX  \n",
       "0           -0.516333            0.090475                     0.193644  \n",
       "1           -0.358187            0.092969                     0.195986  \n",
       "2           -0.230478            0.111993                     0.196811  \n",
       "3           -0.334947            0.215761                     0.206893  \n",
       "4           -0.267834            0.253445                     0.212417  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_body = pd.read_csv(foldtime + ff[:-4]+'.csv')\n",
    "df_body.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One advantage of the output that we get here is that even though we used a 2D video, we get 3D tracking coordinates. This is possible because the MediaPipe detector was trained on hand coordinates for which the depth was known. As the authors state: <i>\"Synthetic dataset: To even better cover the possible hand poses and provide additional supervision for depth, we render a high-quality synthetic hand model over various backgrounds and map it to the corresponding 3D coordinates. We use a commercial 3D hand model that is rigged with 24 bones and includes 36 blendshapes, which control fingers and palm thickness. The model also provides 5 textures with different skin tones. We created video sequences of transformation between hand poses and sampled 100K images from the videos.\" Zhang et al., 2020 </i><br><br>\n",
    "Additionally, the coordinates provided here are given in meters, with the absolute origin (0,0,0) being the center between the hips. This is advantageous because it reduces variability between videos when the distance to camera also varies. <br><br>\n",
    "The major disadvantage to this method is that it is only capable of tracking a single individual at a time. For videos of one speaker/actor, this isn't an issue of course. But if we're interested in multi-party interactions and cannot (or do not wish to) split the video into different individuals (e.g., because of overlapping space between them), we need to use a different solution. We discuss a couple of such options in the modules covering hand tracking with MediaPipe, tracking using DeepLabCut, and tracking using OpenPose."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
